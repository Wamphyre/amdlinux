From 1c3be64de33e2ae996b7343e4a091c6e6f015eda Mon Sep 17 00:00:00 2001
From: Alfred Chen <cchalpha@gmail.com>
Date: Sun, 13 Sep 2020 08:47:44 +0800
Subject: [PATCH] sched/pds: 1.1 Implement bitmap allocator

---
 include/linux/sched.h    |  1 +
 kernel/sched/alt_core.c  | 14 +++---
 kernel/sched/alt_sched.h |  6 +++
 kernel/sched/pds.h       |  9 ++++
 kernel/sched/pds_imp.h   | 92 ++++++++++++++++++++++++++++++++++++++++
 5 files changed, 113 insertions(+), 9 deletions(-)

diff --git a/include/linux/sched.h b/include/linux/sched.h
index 936360572..e5a6ce875 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -703,6 +703,7 @@ struct task_struct {
 	int				sl_level;
 	/* skip list node */
 	struct skiplist_node		sl_node;
+	unsigned int			sln_idx;
 #endif /* CONFIG_SCHED_PDS */
 	/* sched_clock time spent running */
 	u64				sched_time;
diff --git a/kernel/sched/alt_core.c b/kernel/sched/alt_core.c
index bd0144041..1f5c7ce32 100644
--- a/kernel/sched/alt_core.c
+++ b/kernel/sched/alt_core.c
@@ -3516,22 +3516,17 @@ static inline void schedule_debug(struct task_struct *prev, bool preempt)
 	schedstat_inc(this_rq()->sched_count);
 }
 
-/*
- * Compile time debug macro
- * #define ALT_SCHED_DEBUG
- */
-
-#ifdef ALT_SCHED_DEBUG
 void alt_sched_debug(void)
 {
+#ifdef ALT_SCHED_DEBUG
 	printk(KERN_INFO "sched: pending: 0x%04lx, idle: 0x%04lx, sg_idle: 0x%04lx\n",
 	       sched_rq_pending_mask.bits[0],
 	       sched_rq_watermark[IDLE_WM].bits[0],
 	       sched_sg_idle_mask.bits[0]);
-}
-#else
-inline void alt_sched_debug(void) {}
+
+	sched_internal_debug();
 #endif
+}
 
 #ifdef	CONFIG_SMP
 
@@ -6025,6 +6020,7 @@ void __init sched_init(void)
 	struct rq *rq;
 
 	printk(KERN_INFO ALT_SCHED_VERSION_MSG);
+	sched_selftest();
 
 	wait_bit_init();
 
diff --git a/kernel/sched/alt_sched.h b/kernel/sched/alt_sched.h
index fee65eeb1..33668eb43 100644
--- a/kernel/sched/alt_sched.h
+++ b/kernel/sched/alt_sched.h
@@ -48,6 +48,11 @@
 
 #include <trace/events/sched.h>
 
+/*
+ * Compile time debug macro
+ * #define ALT_SCHED_DEBUG
+ */
+
 #ifdef CONFIG_SCHED_BMQ
 #include "bmq.h"
 #endif
@@ -93,6 +98,7 @@ struct rq {
 	struct bmq queue;
 #endif
 #ifdef CONFIG_SCHED_PDS
+	struct skiplist_pool sl_pool;
 	struct skiplist_node sl_header;
 #endif
 	unsigned long watermark;
diff --git a/kernel/sched/pds.h b/kernel/sched/pds.h
index 7fdeace7e..6d1325891 100644
--- a/kernel/sched/pds.h
+++ b/kernel/sched/pds.h
@@ -11,4 +11,13 @@ static inline int task_running_nice(struct task_struct *p)
 	return (p->prio > DEFAULT_PRIO);
 }
 
+#define PDS_INDEX_NUM 32UL
+struct skiplist_pool {
+#ifdef ALT_SCHED_DEBUG
+	unsigned long alloc_count;
+	unsigned long alloc_retry_unique;
+	unsigned long alloc_retry_count;
+#endif
+	unsigned long free_bitmap;
+};
 #endif
diff --git a/kernel/sched/pds_imp.h b/kernel/sched/pds_imp.h
index e1f98a83c..cd6b28187 100644
--- a/kernel/sched/pds_imp.h
+++ b/kernel/sched/pds_imp.h
@@ -1,3 +1,92 @@
+/*
+ * PDS re-implement
+ */
+static void skiplist_pool_init(struct skiplist_pool *slp)
+{
+#ifdef ALT_SCHED_DEBUG
+	slp->alloc_retry_count = 0UL;
+	slp->alloc_retry_unique = 0UL;
+	slp->alloc_count = 0UL;
+#endif
+	slp->free_bitmap = (1UL << PDS_INDEX_NUM) - 1;
+}
+
+static unsigned long skiplist_pool_alloc_index(struct skiplist_pool *slp)
+{
+#ifdef ALT_SCHED_DEBUG
+	int retry = 0;
+	slp->alloc_count++;
+#endif
+	if (slp->free_bitmap) {
+		unsigned long idx = __ffs(slp->free_bitmap);
+		slp->free_bitmap &= ~(1UL << idx);
+
+		return idx;
+	}
+
+	return PDS_INDEX_NUM;
+}
+
+static void skiplist_pool_free_index(struct skiplist_pool *slp,
+				     const unsigned int idx)
+{
+	if (idx >= PDS_INDEX_NUM)
+		return;
+
+	slp->free_bitmap |= (1UL << idx);
+}
+
+static void skiplist_pool_insert(struct rq *rq, struct task_struct *p)
+{
+	p->sln_idx = skiplist_pool_alloc_index(&rq->sl_pool);
+}
+
+static void skiplist_pool_delete(struct rq *rq, struct task_struct *p)
+{
+	skiplist_pool_free_index(&rq->sl_pool, p->sln_idx);
+}
+
+void sched_selftest(void)
+{
+	struct skiplist_pool slp;
+	unsigned int idx[PDS_INDEX_NUM + 1];
+	int i;
+	int count;
+
+	/*
+	 * init skiplist pool
+	 */
+	skiplist_pool_init(&slp);
+
+	printk(KERN_INFO "sched: selftest begin\n");
+	for (count = 0; count < 100000; count++) {
+		for (i = 0; i < PDS_INDEX_NUM + 1; i++)
+			idx[i] = skiplist_pool_alloc_index(&slp);
+		for (i = 0; i < PDS_INDEX_NUM + 1; i++)
+			skiplist_pool_free_index(&slp, idx[i]);
+
+		BUG_ON(((1UL << PDS_INDEX_NUM) - 1 ) != slp.free_bitmap);
+	}
+	printk(KERN_INFO "sched: selftest end\n");
+}
+
+#ifdef ALT_SCHED_DEBUG
+void skiplist_pool_debug(const struct skiplist_pool *slp)
+{
+	printk(KERN_INFO "sched: skiplist_pool alloc %lu/%lu/%lu\n",
+	       slp->alloc_retry_count, slp->alloc_retry_unique,
+	       slp->alloc_count);
+}
+
+void sched_internal_debug(void)
+{
+	int i;
+
+	for (i = 0; i < 8; i++)
+		skiplist_pool_debug(&cpu_rq(i)->sl_pool);
+}
+#endif
+
 #define ALT_SCHED_VERSION_MSG "sched/pds: PDS CPU Scheduler "ALT_SCHED_VERSION" by Alfred Chen.\n"
 
 static const u64 user_prio2deadline[NICE_WIDTH] = {
@@ -90,6 +179,7 @@ DEFINE_SKIPLIST_INSERT_FUNC(pds_skiplist_insert, pds_skiplist_task_search);
 static inline void sched_queue_init(struct rq *rq)
 {
 	FULL_INIT_SKIPLIST_NODE(&rq->sl_header);
+	skiplist_pool_init(&rq->sl_pool);
 }
 
 /*
@@ -142,6 +232,7 @@ static inline unsigned long sched_queue_watermark(struct rq *rq)
 	psi_dequeue(p, flags & DEQUEUE_SLEEP);			\
 	sched_info_dequeued(rq, p);				\
 								\
+	skiplist_pool_delete(rq, p);					\
 	if (skiplist_del_init(&rq->sl_header, &p->sl_node)) {	\
 		func;						\
 	}
@@ -150,6 +241,7 @@ static inline unsigned long sched_queue_watermark(struct rq *rq)
 	sched_info_queued(rq, p);					\
 	psi_enqueue(p, flags);						\
 									\
+	skiplist_pool_insert(rq, p);						\
 	p->sl_node.level = p->sl_level;					\
 	pds_skiplist_insert(&rq->sl_header, &p->sl_node)
 
-- 
2.29.0

