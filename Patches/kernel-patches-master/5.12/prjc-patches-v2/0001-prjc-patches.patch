From f325de560b66b34b2addce99572322fcd437c49e Mon Sep 17 00:00:00 2001
From: Alfred Chen <cchalpha@gmail.com>
Date: Thu, 1 Apr 2021 09:57:05 +0800
Subject: [PATCH 1/7] sched/alt: Cleanup in cpufreq_schedutil.c

---
 kernel/sched/cpufreq_schedutil.c | 9 ++-------
 1 file changed, 2 insertions(+), 7 deletions(-)

diff --git a/kernel/sched/cpufreq_schedutil.c b/kernel/sched/cpufreq_schedutil.c
index fb703fd370fd..41946f19468b 100644
--- a/kernel/sched/cpufreq_schedutil.c
+++ b/kernel/sched/cpufreq_schedutil.c
@@ -903,10 +903,11 @@ struct cpufreq_governor *cpufreq_default_governor(void)
 cpufreq_governor_init(schedutil_gov);
 
 #ifdef CONFIG_ENERGY_MODEL
-#ifndef CONFIG_SCHED_ALT
 static void rebuild_sd_workfn(struct work_struct *work)
 {
+#ifndef CONFIG_SCHED_ALT
 	rebuild_sched_domains_energy();
+#endif /* CONFIG_SCHED_ALT */
 }
 static DECLARE_WORK(rebuild_sd_work, rebuild_sd_workfn);
 
@@ -927,10 +928,4 @@ void sched_cpufreq_governor_change(struct cpufreq_policy *policy,
 	}
 
 }
-#else /* CONFIG_SCHED_ALT */
-void sched_cpufreq_governor_change(struct cpufreq_policy *policy,
-				  struct cpufreq_governor *old_gov)
-{
-}
-#endif
 #endif
-- 
2.31.1.362.g311531c9de


From 61bae98e216d4493b25daac06153dac5426d46a0 Mon Sep 17 00:00:00 2001
From: Alfred Chen <cchalpha@gmail.com>
Date: Fri, 26 Mar 2021 13:46:22 +0800
Subject: [PATCH 2/7] sched/alt: Remove unnecessary CONFIG_SMP macros usage.

---
 kernel/sched/alt_core.c | 6 ++----
 1 file changed, 2 insertions(+), 4 deletions(-)

diff --git a/kernel/sched/alt_core.c b/kernel/sched/alt_core.c
index 02610d086d00..ae37764ced1e 100644
--- a/kernel/sched/alt_core.c
+++ b/kernel/sched/alt_core.c
@@ -3816,15 +3816,13 @@ static inline int take_other_rq_tasks(struct rq *rq, int cpu)
 
 			if ((nr_migrated = migrate_pending_tasks(src_rq, rq, cpu))) {
 				src_rq->nr_running -= nr_migrated;
-#ifdef CONFIG_SMP
 				if (src_rq->nr_running < 2)
 					cpumask_clear_cpu(i, &sched_rq_pending_mask);
-#endif
+
 				rq->nr_running += nr_migrated;
-#ifdef CONFIG_SMP
 				if (rq->nr_running > 1)
 					cpumask_set_cpu(cpu, &sched_rq_pending_mask);
-#endif
+
 				update_sched_rq_watermark(rq);
 				cpufreq_update_util(rq, 0);
 
-- 
2.31.1.362.g311531c9de


From 9cc476f40e6f3ee9e9ae1bf33a547f085e498593 Mon Sep 17 00:00:00 2001
From: Alfred Chen <cchalpha@gmail.com>
Date: Sun, 4 Apr 2021 08:54:29 +0800
Subject: [PATCH 3/7] sched/alt: Code clean up

---
 kernel/sched/alt_core.c | 11 +----------
 1 file changed, 1 insertion(+), 10 deletions(-)

diff --git a/kernel/sched/alt_core.c b/kernel/sched/alt_core.c
index ae37764ced1e..3e79fdc14152 100644
--- a/kernel/sched/alt_core.c
+++ b/kernel/sched/alt_core.c
@@ -1138,20 +1138,11 @@ void set_task_cpu(struct task_struct *p, unsigned int new_cpu)
 	__set_task_cpu(p, new_cpu);
 }
 
-static inline bool is_per_cpu_kthread(struct task_struct *p)
-{
-	return ((p->flags & PF_KTHREAD) && (1 == p->nr_cpus_allowed));
-}
-
 #define MDF_FORCE_ENABLED	0x80
 
 static void
 __do_set_cpus_allowed(struct task_struct *p, const struct cpumask *new_mask, u32 flags);
 
-static int __set_cpus_allowed_ptr(struct task_struct *p,
-				  const struct cpumask *new_mask,
-				  u32 flags);
-
 void migrate_disable(void)
 {
 	struct task_struct *p = current;
@@ -1753,7 +1744,7 @@ static int __set_cpus_allowed_ptr(struct task_struct *p,
 		goto out;
 
 	if (p->migration_disabled) {
-		if (p->cpus_ptr != &p->cpus_mask)
+		if (likely(p->cpus_ptr != &p->cpus_mask))
 			__do_set_cpus_allowed(p, &p->cpus_mask, SCA_MIGRATE_ENABLE);
 		p->migration_disabled = 0;
 		p->migration_flags |= MDF_FORCE_ENABLED;
-- 
2.31.1.362.g311531c9de


From 5e1cab364aa76e719c723411b982da222d111df3 Mon Sep 17 00:00:00 2001
From: Alfred Chen <cchalpha@gmail.com>
Date: Wed, 7 Apr 2021 11:43:30 +0800
Subject: [PATCH 4/7] sched/alt: Don't migrate_disable() during migration.

---
 kernel/sched/alt_core.c | 21 ++++++++++++---------
 1 file changed, 12 insertions(+), 9 deletions(-)

diff --git a/kernel/sched/alt_core.c b/kernel/sched/alt_core.c
index 3e79fdc14152..11ffc1cb4528 100644
--- a/kernel/sched/alt_core.c
+++ b/kernel/sched/alt_core.c
@@ -1146,6 +1146,7 @@ __do_set_cpus_allowed(struct task_struct *p, const struct cpumask *new_mask, u32
 void migrate_disable(void)
 {
 	struct task_struct *p = current;
+	int cpu;
 
 	if (p->migration_disabled) {
 		p->migration_disabled++;
@@ -1153,16 +1154,18 @@ void migrate_disable(void)
 	}
 
 	preempt_disable();
-	this_rq()->nr_pinned++;
-	p->migration_disabled = 1;
-	p->migration_flags &= ~MDF_FORCE_ENABLED;
-
-	/*
-	 * Violates locking rules! see comment in __do_set_cpus_allowed().
-	 */
-	if (p->cpus_ptr == &p->cpus_mask)
-		__do_set_cpus_allowed(p, cpumask_of(smp_processor_id()), SCA_MIGRATE_DISABLE);
+	cpu = smp_processor_id();
+	if (cpumask_test_cpu(cpu, &p->cpus_mask)) {
+		cpu_rq(cpu)->nr_pinned++;
+		p->migration_disabled = 1;
+		p->migration_flags &= ~MDF_FORCE_ENABLED;
 
+		/*
+		 * Violates locking rules! see comment in __do_set_cpus_allowed().
+		 */
+		if (p->cpus_ptr == &p->cpus_mask)
+			__do_set_cpus_allowed(p, cpumask_of(cpu), SCA_MIGRATE_DISABLE);
+	}
 	preempt_enable();
 }
 EXPORT_SYMBOL_GPL(migrate_disable);
-- 
2.31.1.362.g311531c9de


From 08ed9c10e21a0166fc731808dfb301309d4ece6e Mon Sep 17 00:00:00 2001
From: Alfred Chen <cchalpha@gmail.com>
Date: Wed, 7 Apr 2021 14:08:18 +0800
Subject: [PATCH 5/7] sched/alt: migrate disable code clean up

---
 kernel/sched/alt_core.c | 63 ++++++++++++++++++-----------------------
 1 file changed, 28 insertions(+), 35 deletions(-)

diff --git a/kernel/sched/alt_core.c b/kernel/sched/alt_core.c
index 11ffc1cb4528..4ed1ff9f1aab 100644
--- a/kernel/sched/alt_core.c
+++ b/kernel/sched/alt_core.c
@@ -1097,8 +1097,6 @@ static inline bool is_migration_disabled(struct task_struct *p)
 }
 
 #define SCA_CHECK		0x01
-#define SCA_MIGRATE_DISABLE	0x02
-#define SCA_MIGRATE_ENABLE	0x04
 
 #ifdef CONFIG_SMP
 
@@ -1141,7 +1139,23 @@ void set_task_cpu(struct task_struct *p, unsigned int new_cpu)
 #define MDF_FORCE_ENABLED	0x80
 
 static void
-__do_set_cpus_allowed(struct task_struct *p, const struct cpumask *new_mask, u32 flags);
+__do_set_cpus_ptr(struct task_struct *p, const struct cpumask *new_mask)
+{
+	/*
+	 * This here violates the locking rules for affinity, since we're only
+	 * supposed to change these variables while holding both rq->lock and
+	 * p->pi_lock.
+	 *
+	 * HOWEVER, it magically works, because ttwu() is the only code that
+	 * accesses these variables under p->pi_lock and only does so after
+	 * smp_cond_load_acquire(&p->on_cpu, !VAL), and we're in __schedule()
+	 * before finish_task().
+	 *
+	 * XXX do further audits, this smells like something putrid.
+	 */
+	SCHED_WARN_ON(!p->on_cpu);
+	p->cpus_ptr = new_mask;
+}
 
 void migrate_disable(void)
 {
@@ -1161,10 +1175,10 @@ void migrate_disable(void)
 		p->migration_flags &= ~MDF_FORCE_ENABLED;
 
 		/*
-		 * Violates locking rules! see comment in __do_set_cpus_allowed().
+		 * Violates locking rules! see comment in __do_set_cpus_ptr().
 		 */
 		if (p->cpus_ptr == &p->cpus_mask)
-			__do_set_cpus_allowed(p, cpumask_of(cpu), SCA_MIGRATE_DISABLE);
+			__do_set_cpus_ptr(p, cpumask_of(cpu));
 	}
 	preempt_enable();
 }
@@ -1192,7 +1206,7 @@ void migrate_enable(void)
 	 */
 	WARN_ON_ONCE(!cpumask_test_cpu(smp_processor_id(), &p->cpus_mask));
 	if (p->cpus_ptr != &p->cpus_mask)
-		__do_set_cpus_allowed(p, &p->cpus_mask, SCA_MIGRATE_ENABLE);
+		__do_set_cpus_ptr(p, &p->cpus_mask);
 	/*
 	 * Mustn't clear migration_disabled() until cpus_ptr points back at the
 	 * regular cpus_mask, otherwise things that race (eg.
@@ -1345,43 +1359,22 @@ static int migration_cpu_stop(void *data)
 }
 
 static inline void
-set_cpus_allowed_common(struct task_struct *p, const struct cpumask *new_mask, u32 flags)
+set_cpus_allowed_common(struct task_struct *p, const struct cpumask *new_mask)
 {
-	if (flags & (SCA_MIGRATE_ENABLE | SCA_MIGRATE_DISABLE)) {
-		p->cpus_ptr = new_mask;
-		return;
-	}
-
 	cpumask_copy(&p->cpus_mask, new_mask);
 	p->nr_cpus_allowed = cpumask_weight(new_mask);
 }
 
 static void
-__do_set_cpus_allowed(struct task_struct *p, const struct cpumask *new_mask, u32 flags)
+__do_set_cpus_allowed(struct task_struct *p, const struct cpumask *new_mask)
 {
-	/*
-	 * This here violates the locking rules for affinity, since we're only
-	 * supposed to change these variables while holding both rq->lock and
-	 * p->pi_lock.
-	 *
-	 * HOWEVER, it magically works, because ttwu() is the only code that
-	 * accesses these variables under p->pi_lock and only does so after
-	 * smp_cond_load_acquire(&p->on_cpu, !VAL), and we're in __schedule()
-	 * before finish_task().
-	 *
-	 * XXX do further audits, this smells like something putrid.
-	 */
-	if (flags & (SCA_MIGRATE_DISABLE | SCA_MIGRATE_ENABLE))
-		SCHED_WARN_ON(!p->on_cpu);
-	else
-		lockdep_assert_held(&p->pi_lock);
-
-	set_cpus_allowed_common(p, new_mask, flags);
+	lockdep_assert_held(&p->pi_lock);
+	set_cpus_allowed_common(p, new_mask);
 }
 
 void do_set_cpus_allowed(struct task_struct *p, const struct cpumask *new_mask)
 {
-	__do_set_cpus_allowed(p, new_mask, 0);
+	__do_set_cpus_allowed(p, new_mask);
 }
 
 #endif
@@ -1740,7 +1733,7 @@ static int __set_cpus_allowed_ptr(struct task_struct *p,
 		goto out;
 	}
 
-	__do_set_cpus_allowed(p, new_mask, flags);
+	__do_set_cpus_allowed(p, new_mask);
 
 	/* Can the task run on the task's current CPU? If so, we're done */
 	if (cpumask_test_cpu(task_cpu(p), new_mask))
@@ -1748,7 +1741,7 @@ static int __set_cpus_allowed_ptr(struct task_struct *p,
 
 	if (p->migration_disabled) {
 		if (likely(p->cpus_ptr != &p->cpus_mask))
-			__do_set_cpus_allowed(p, &p->cpus_mask, SCA_MIGRATE_ENABLE);
+			__do_set_cpus_ptr(p, &p->cpus_mask);
 		p->migration_disabled = 0;
 		p->migration_flags |= MDF_FORCE_ENABLED;
 		/* When p is migrate_disabled, rq->lock should be held */
@@ -6076,7 +6069,7 @@ void init_idle(struct task_struct *idle, int cpu)
 	 *
 	 * And since this is boot we can forgo the serialisation.
 	 */
-	set_cpus_allowed_common(idle, cpumask_of(cpu), 0);
+	set_cpus_allowed_common(idle, cpumask_of(cpu));
 #endif
 
 	/* Silence PROVE_RCU */
-- 
2.31.1.362.g311531c9de


From 301316e82d12eeefe0ae0ad4f842ca91b672549a Mon Sep 17 00:00:00 2001
From: Alfred Chen <cchalpha@gmail.com>
Date: Mon, 19 Apr 2021 10:11:56 +0800
Subject: [PATCH 6/7] sched/alt: Fix task migratie to dying cpu.

Fix #23

WARNING: CPU: 2 PID: 26 at kernel/sched/alt_core.c:6294
sched_cpu_dying.cold+0xc/0xd2
---
 kernel/sched/alt_core.c | 6 +++++-
 1 file changed, 5 insertions(+), 1 deletion(-)

diff --git a/kernel/sched/alt_core.c b/kernel/sched/alt_core.c
index 4ed1ff9f1aab..6350afe33985 100644
--- a/kernel/sched/alt_core.c
+++ b/kernel/sched/alt_core.c
@@ -1619,7 +1619,7 @@ static inline int select_task_rq(struct task_struct *p, struct rq *rq)
 {
 	cpumask_t chk_mask, tmp;
 
-	if (unlikely(!cpumask_and(&chk_mask, p->cpus_ptr, cpu_online_mask)))
+	if (unlikely(!cpumask_and(&chk_mask, p->cpus_ptr, cpu_active_mask)))
 		return select_fallback_rq(task_cpu(p), p);
 
 	if (
@@ -3420,6 +3420,10 @@ static inline void sg_balance_check(struct rq *rq)
 	if (cpumask_empty(&sched_sg_idle_mask))
 		return;
 
+	/* exit when cpu is offline */
+	if (unlikely(!rq->online))
+		return;
+
 	cpu = cpu_of(rq);
 	/*
 	 * Only cpu in slibing idle group will do the checking and then
-- 
2.31.1.362.g311531c9de


From e894eaab4089b0fcdcba6426913f0d75b9243be8 Mon Sep 17 00:00:00 2001
From: Alfred Chen <cchalpha@gmail.com>
Date: Tue, 27 Apr 2021 10:37:22 +0800
Subject: [PATCH 7/7] Project-C v5.12-r1

---
 kernel/sched/alt_core.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/kernel/sched/alt_core.c b/kernel/sched/alt_core.c
index 6350afe33985..c85e3ccf9302 100644
--- a/kernel/sched/alt_core.c
+++ b/kernel/sched/alt_core.c
@@ -52,7 +52,7 @@
  */
 EXPORT_TRACEPOINT_SYMBOL_GPL(pelt_irq_tp);
 
-#define ALT_SCHED_VERSION "v5.12-r0"
+#define ALT_SCHED_VERSION "v5.12-r1"
 
 /* rt_prio(prio) defined in include/linux/sched/rt.h */
 #define rt_task(p)		rt_prio((p)->prio)
-- 
2.31.1.362.g311531c9de

